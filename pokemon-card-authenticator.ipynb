{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction #\n\nThanks to Kaggle mini-courses on computer vision for getting me started on this.\nMy first trained CNN to classify the card images heavily inspired by Francesco Marazz's CNN (https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb) for the Histopathologic Cancer Detection competition (https://www.kaggle.com/c/histopathologic-cancer-detection).\n\nMy objective here is to build my first image classifier using Keras. Rare Pokemon cards are highly sought after by collectors, with some even reaching re-sale prices of hundreds of thousands of dollars. It would be important for collectors to tell a genuine card from fake card to avoid getting duped. Experienced collectors are able to tell the different between a genuine and fake card by looking at the features of the back of the card alone, but this might not be so obvious for newcomers. The image classifier described below will aim to classify, with high accuracy (>95%), Pokemon cards as genuine or fake based on the back visuals of the card alone. In future work, the model can be made more robust by including more counterfeit variations, folded, torn, new and old cards in the training, validation and test sets.","metadata":{}},{"cell_type":"markdown","source":"# Load Data #","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport shutil\nprint(os.listdir(\"../input\"))\n\nfrom glob import glob \nfrom skimage.io import imread\nimport gc\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:29.629891Z","iopub.execute_input":"2022-02-27T05:57:29.630145Z","iopub.status.idle":"2022-02-27T05:57:30.745406Z","shell.execute_reply.started":"2022-02-27T05:57:29.630115Z","shell.execute_reply":"2022-02-27T05:57:30.744648Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"base_tile_dir = '../input/real-and-fake-pokemon-cards/train'\ndf = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.JPG'))})\ndf['id'] = df.path.map(lambda x: x.split('/')[4].split(\".\")[0])\nlabels = pd.read_csv(\"../input/real-and-fake-pokemon-cards/train_labels.csv\")\nlabels['id'] = labels['id'].astype('str')\nlabels = labels.sort_values(by=['id'], ignore_index = True)\ndf['id'] = df['id'].astype('str')\ndf = df.sort_values(by=['id'], ignore_index = True)\ndf_data = pd.merge(labels, df, on=\"id\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:30.746792Z","iopub.execute_input":"2022-02-27T05:57:30.747409Z","iopub.status.idle":"2022-02-27T05:57:30.870725Z","shell.execute_reply.started":"2022-02-27T05:57:30.747321Z","shell.execute_reply":"2022-02-27T05:57:30.870011Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization #","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef readImage(path):\n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    return rgb_img","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:32.876070Z","iopub.execute_input":"2022-02-27T05:57:32.876316Z","iopub.status.idle":"2022-02-27T05:57:33.121696Z","shell.execute_reply.started":"2022-02-27T05:57:32.876289Z","shell.execute_reply":"2022-02-27T05:57:33.121009Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# random sampling\nshuffled_data = shuffle(df_data)\n\nfig, ax = plt.subplots(2,5, figsize=(20,8))\nfig.suptitle('Real and Fake Pokemon Cards',fontsize=20)\n# Real\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 1]['id'][:5]):\n    path = os.path.join(base_tile_dir, idx)\n    ax[0,i].imshow(readImage(path + '.JPG'))\nax[0,0].set_ylabel('Real Cards', size='large')\n# Fake\nfor i, idx in enumerate(shuffled_data[shuffled_data['label'] == 0]['id'][:5]):\n    path = os.path.join(base_tile_dir, idx)\n    ax[1,i].imshow(readImage(path + '.JPG'))\nax[1,0].set_ylabel('Fake Cards', size='large')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:34.254473Z","iopub.execute_input":"2022-02-27T05:57:34.254772Z","iopub.status.idle":"2022-02-27T05:57:35.702781Z","shell.execute_reply.started":"2022-02-27T05:57:34.254739Z","shell.execute_reply":"2022-02-27T05:57:35.702144Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Split X and y in train/test and build folders\n","metadata":{}},{"cell_type":"code","source":"# Set the id as the index in df_data\ndf_data.set_index('id', inplace=True)\ndf_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:35.969450Z","iopub.execute_input":"2022-02-27T05:57:35.969662Z","iopub.status.idle":"2022-02-27T05:57:35.983022Z","shell.execute_reply.started":"2022-02-27T05:57:35.969635Z","shell.execute_reply":"2022-02-27T05:57:35.982305Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# train_test_split # stratify=y creates a balanced validation set.\ny = df_data['label']\ndf_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:37.153650Z","iopub.execute_input":"2022-02-27T05:57:37.154411Z","iopub.status.idle":"2022-02-27T05:57:37.163006Z","shell.execute_reply.started":"2022-02-27T05:57:37.154347Z","shell.execute_reply":"2022-02-27T05:57:37.162162Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Create directories\ntrain_path = 'base_dir/train'\nvalid_path = 'base_dir/valid'\ntest_path = '../input/real-and-fake-pokemon-cards/test'\nfor fold in [train_path, valid_path]:\n    for subf in [\"0\", \"1\"]:\n        os.makedirs(os.path.join(fold, subf))","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:40.035794Z","iopub.execute_input":"2022-02-27T05:57:40.036056Z","iopub.status.idle":"2022-02-27T05:57:40.042381Z","shell.execute_reply.started":"2022-02-27T05:57:40.036026Z","shell.execute_reply":"2022-02-27T05:57:40.041419Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for image in df_train.index.values:\n    # the id in the csv file does not have the .JPG extension therefore we add it here\n    fname = image + '.JPG'\n    label = str(df_data.loc[image,'label']) # get the label for a certain image\n    src = os.path.join('../input/real-and-fake-pokemon-cards/train', fname)\n    dst = os.path.join(train_path, label, fname)\n    shutil.copyfile(src, dst)\n\nfor image in df_val.index.values:\n    fname = image + '.JPG'\n    label = str(df_data.loc[image,'label']) # get the label for a certain image\n    src = os.path.join('../input/real-and-fake-pokemon-cards/train', fname)\n    dst = os.path.join(valid_path, label, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:41.273424Z","iopub.execute_input":"2022-02-27T05:57:41.274393Z","iopub.status.idle":"2022-02-27T05:57:43.307795Z","shell.execute_reply.started":"2022-02-27T05:57:41.274327Z","shell.execute_reply":"2022-02-27T05:57:43.306889Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nIMAGE_SIZE = 256\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 32\nval_batch_size = 32\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)\n\ndatagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n                            horizontal_flip=True,\n                            vertical_flip=True)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='binary')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='binary')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='binary',\n                                        shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:43.309379Z","iopub.execute_input":"2022-02-27T05:57:43.309883Z","iopub.status.idle":"2022-02-27T05:57:43.623294Z","shell.execute_reply.started":"2022-02-27T05:57:43.309842Z","shell.execute_reply":"2022-02-27T05:57:43.622655Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Define the model \n**Model structure (optimizer: Adam):**\n\n* In \n* [Conv2D*3 -> MaxPool2D -> Dropout] x3 --> (filters = 16, 32, 64)\n* Flatten \n* Dense (256) \n* Dropout \n* Out","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop, Adam\n\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.5\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n#model.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\n# Compile the model\nmodel.compile(Adam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:44.932767Z","iopub.execute_input":"2022-02-27T05:57:44.933011Z","iopub.status.idle":"2022-02-27T05:57:47.279249Z","shell.execute_reply.started":"2022-02-27T05:57:44.932982Z","shell.execute_reply":"2022-02-27T05:57:47.278525Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndot_img_file = '/tmp/model_1.png'\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:47.281458Z","iopub.execute_input":"2022-02-27T05:57:47.281949Z","iopub.status.idle":"2022-02-27T05:57:48.230819Z","shell.execute_reply.started":"2022-02-27T05:57:47.281912Z","shell.execute_reply":"2022-02-27T05:57:48.229060Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\nreducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=50,\n                   callbacks=[reducel, earlystopper])","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:57:48.232811Z","iopub.execute_input":"2022-02-27T05:57:48.233507Z","iopub.status.idle":"2022-02-27T05:59:28.375739Z","shell.execute_reply.started":"2022-02-27T05:57:48.233469Z","shell.execute_reply":"2022-02-27T05:59:28.375026Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# make a prediction\ny_pred_keras = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\nauc_keras = auc(fpr_keras, tpr_keras)\nauc_keras","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:59:32.034376Z","iopub.execute_input":"2022-02-27T05:59:32.034917Z","iopub.status.idle":"2022-02-27T05:59:32.294214Z","shell.execute_reply.started":"2022-02-27T05:59:32.034878Z","shell.execute_reply":"2022-02-27T05:59:32.293534Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Plot ROC Curve","metadata":{}},{"cell_type":"code","source":"plt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T05:59:35.058812Z","iopub.execute_input":"2022-02-27T05:59:35.059065Z","iopub.status.idle":"2022-02-27T05:59:35.246847Z","shell.execute_reply.started":"2022-02-27T05:59:35.059035Z","shell.execute_reply":"2022-02-27T05:59:35.246163Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Load test data and predict\n","metadata":{}},{"cell_type":"code","source":"base_test_dir = '../input/real-and-fake-pokemon-cards/test'\ntest_files = glob(os.path.join(base_test_dir,'*.JPG'))\nsubmission = pd.DataFrame()\nfile_batch = 78\nmax_idx = len(test_files)\nfor idx in range(0, max_idx, file_batch):\n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n    test_df['id'] = test_df.path.map(lambda x: x.split('/')[4].split(\".\")[0])\n    test_df['image'] = test_df['path'].map(imread)\n    K_test = np.stack(test_df[\"image\"].values)\n    K_test = (K_test - K_test.mean()) / K_test.std()\n    predictions = model.predict(K_test)\n    predictions = list(map(lambda x: 0 if x<0.5 else 1, predictions)) # get binary values predictions with 0.5 as thresold\n    test_df['predict'] = predictions\n    submission = pd.concat([submission, test_df[[\"id\", \"predict\"]]])\nsubmission.head()\ndf_test = pd.read_csv('../input/real-and-fake-pokemon-cards/test_labels.csv')\ndf_test['id'] = df_test['id'].astype('str')\ncheck_results = pd.merge(submission, df_test, on='id')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:00:44.822607Z","iopub.execute_input":"2022-02-27T06:00:44.823276Z","iopub.status.idle":"2022-02-27T06:00:45.495429Z","shell.execute_reply.started":"2022-02-27T06:00:44.823238Z","shell.execute_reply":"2022-02-27T06:00:45.494667Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"check_results","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:01:30.227916Z","iopub.execute_input":"2022-02-27T06:01:30.228174Z","iopub.status.idle":"2022-02-27T06:01:30.243869Z","shell.execute_reply.started":"2022-02-27T06:01:30.228144Z","shell.execute_reply":"2022-02-27T06:01:30.242744Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nmodel_accuracy = accuracy_score(check_results['label'],check_results['predict'])\nprint('Accuracy =', model_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T06:01:32.821766Z","iopub.execute_input":"2022-02-27T06:01:32.822318Z","iopub.status.idle":"2022-02-27T06:01:32.829023Z","shell.execute_reply.started":"2022-02-27T06:01:32.822279Z","shell.execute_reply":"2022-02-27T06:01:32.828322Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"check_results.to_csv(\"results.csv\", index = False, header = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T16:28:44.526152Z","iopub.execute_input":"2022-02-26T16:28:44.526602Z","iopub.status.idle":"2022-02-26T16:28:44.535655Z","shell.execute_reply.started":"2022-02-26T16:28:44.526551Z","shell.execute_reply":"2022-02-26T16:28:44.534557Z"},"trusted":true},"execution_count":null,"outputs":[]}]}